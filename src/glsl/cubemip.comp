#version 460
#pragma shader_stage(compute)
#extension GL_EXT_nonuniform_qualifier: enable

layout(local_size_x = 16, local_size_y = 16) in;

layout(set = 0, binding = 0, rgba16f) restrict coherent uniform image2DArray cubemap[];
layout(set = 1, binding = 0) restrict coherent buffer Atomics {
	uint groupsFinished[6];
};
layout(set = 1, binding = 1) uniform sampler2DArray cubemapBase;

const uint groupSize = gl_WorkGroupSize.x;

shared vec4 localArea[groupSize * groupSize];
shared bool finalGroup;

vec4 LocalLoad(uvec2 id) {
	return localArea[id.y * groupSize + id.x];
}

void LocalStore(uvec2 id, vec4 val) {
	localArea[id.y * groupSize + id.x] = val;
}

void main() {
	const uvec3 gid = gl_GlobalInvocationID;
	const uvec3 lid = gl_LocalInvocationID;
	const uvec3 wid = gl_WorkGroupID;

	if (gid.xy == uvec2(0))
		atomicExchange(groupsFinished[gid.z], 0);

	const vec2 tex = vec2(1.0) / vec2(textureSize(cubemapBase, 0).xy);
	vec4 sample00 = textureLod(cubemapBase, vec3(tex * vec2(gid.xy * 4 + uvec2(1, 1)), gid.z), 0.0);
	vec4 sample10 = textureLod(cubemapBase, vec3(tex * vec2(gid.xy * 4 + uvec2(3, 1)), gid.z), 0.0);
	vec4 sample01 = textureLod(cubemapBase, vec3(tex * vec2(gid.xy * 4 + uvec2(1, 3)), gid.z), 0.0);
	vec4 sample11 = textureLod(cubemapBase, vec3(tex * vec2(gid.xy * 4 + uvec2(3, 3)), gid.z), 0.0);
	imageStore(cubemap[1], ivec3(gid.xy * 2 + uvec2(0, 0), gid.z), sample00);
	imageStore(cubemap[1], ivec3(gid.xy * 2 + uvec2(1, 0), gid.z), sample10);
	imageStore(cubemap[1], ivec3(gid.xy * 2 + uvec2(0, 1), gid.z), sample01);
	imageStore(cubemap[1], ivec3(gid.xy * 2 + uvec2(1, 1), gid.z), sample11);
	vec4 sampleAvg = (sample00 + sample10 + sample01 + sample11) * 0.25;
	imageStore(cubemap[2], ivec3(gid.xy, gid.z), sampleAvg);
	LocalStore(lid.xy, sampleAvg);

	uint mip = 3;
	for (uint step = 1; step < gl_WorkGroupSize.x; step *= 2) {

		memoryBarrierShared();
		barrier();

		uint threshold = groupSize / (step * 2);
		bool isActive = (lid.x < threshold && lid.y < threshold);
		if (isActive) {
			vec4 sample00 = LocalLoad(lid.xy * step * 2 + uvec2(0, 0));
			vec4 sample10 = LocalLoad(lid.xy * step * 2 + uvec2(step, 0));
			vec4 sample01 = LocalLoad(lid.xy * step * 2 + uvec2(0, step));
			vec4 sample11 = LocalLoad(lid.xy * step * 2 + uvec2(step, step));
			vec4 sampleAvg = (sample00 + sample10 + sample01 + sample11) * 0.25;
			imageStore(cubemap[mip], ivec3(wid.xy * (groupSize / (step * 2)) + lid.xy, gid.z), sampleAvg);
			LocalStore(lid.xy * step * 2, sampleAvg);
		}

		mip += 1;
	}

	if (lid.xy == uvec2(0)) {
		uint groupFinishIndex = atomicAdd(groupsFinished[gid.z], 1) + 1;
		finalGroup = (groupFinishIndex == groupSize * groupSize);
	}

	memoryBarrierShared();
	memoryBarrierImage();
	barrier();

	if (finalGroup) {

		vec4 groupSample = imageLoad(cubemap[mip-1], ivec3(lid.xy, gid.z));
		LocalStore(lid.xy, groupSample);

		for (uint step = 1; step < gl_WorkGroupSize.x; step *= 2) {

			memoryBarrierShared();
			barrier();

			uint threshold = groupSize / (step * 2);
			bool isActive = (lid.x < threshold && lid.y < threshold);
			if (isActive) {
				vec4 sample00 = LocalLoad(lid.xy * step * 2 + uvec2(0, 0));
				vec4 sample10 = LocalLoad(lid.xy * step * 2 + uvec2(step, 0));
				vec4 sample01 = LocalLoad(lid.xy * step * 2 + uvec2(0, step));
				vec4 sample11 = LocalLoad(lid.xy * step * 2 + uvec2(step, step));
				vec4 sampleAvg = (sample00 + sample10 + sample01 + sample11) * 0.25;
				imageStore(cubemap[mip], ivec3(lid.xy, gid.z), sampleAvg);
				LocalStore(lid.xy * step * 2, sampleAvg);
			}

			mip += 1;
		}

	}
}
